<h1>Assessing LLMs to Improve the Prediction of COVID-19 Status</h1>
<p>
    Official website: <a href="https://ramosrenzo.github.io/COVID-LLM/" target="_blank">Assessing LLMs to Improve the Prediction of COVID-19 Status</a>
</p>

<h2>Abstract</h2>
<p>
    In this study, we assess the performance of four large language models (LLMs)—
    DNABERT, DNABERT-2, GROVER and AAM—in predicting COVID-19 status
    from microbiome data. Given the increasing recognition of the microbiome’s
    role in health outcomes, we focus on how the pretraining of these models
    impacts their predictive capabilities. These four models were chosen for their
    distinct pre-training strategies: DNABERT and GROVER were trained on the
    human genome, DNABERT-2 incorporated multi-species genomes, and AAM
    was trained on 16s ribosomal RNA (rRNA) sequencing data. We assessed each
    model’s performance by using embeddings extracted from fecal and hospital-
    derived 16s data labeled with COVID-19 status. For our evaluation metrics,
    we used AUROC and AUPRC to benchmark.
</p>

