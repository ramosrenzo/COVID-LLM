{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install torcheval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kathleennguyen/anaconda3/envs/covid_llms/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, BertConfig, logging\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torcheval.metrics.functional import binary_auroc, binary_auprc\n",
    "from torchmetrics import AUROC\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biom import load_table, Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorDataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        table = None,\n",
    "        metadata = None,\n",
    "        metadata_column = None,\n",
    "        shift = None,\n",
    "        scale = \"minmax\",\n",
    "        max_token_per_sample: int = 1024,\n",
    "        shuffle: bool = False,\n",
    "        rarefy_depth: int = 5000,\n",
    "        epochs: int = 1000,\n",
    "        gen_new_tables: bool = False,\n",
    "        batch_size: int = 8,\n",
    "        max_bp: int = 150,\n",
    "        is_16S: bool = True,\n",
    "        is_categorical = None,\n",
    "        gen_new_table_frequency=3,\n",
    "        return_sample_ids=False,\n",
    "        tree_path=None,\n",
    "        seed=None,\n",
    "    ):\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        # initialize tokenizer and model\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
    "        self.config = BertConfig.from_pretrained(\"zhihan1996/DNABERT-2-117M\")\n",
    "        self.model = AutoModel.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True, config=self.config).to(device)\n",
    "        self.model.requires_grad = False\n",
    "\n",
    "        if isinstance(table, str):\n",
    "            table = load_table(table)\n",
    "        self.table: Table = table\n",
    "        self.tree_path = tree_path\n",
    "        self.is_categorical: bool = is_categorical\n",
    "        self.metadata_column: str = metadata_column\n",
    "        self.shift = shift\n",
    "        self.scale = scale\n",
    "        self.metadata: pd.Series = metadata\n",
    "        self.rarefy_depth: int = rarefy_depth\n",
    "        self.max_token_per_sample: int = max_token_per_sample\n",
    "        self.return_sample_ids: bool = return_sample_ids\n",
    "        self.include_sample_weight: bool = is_categorical\n",
    "        self.shuffle = shuffle\n",
    "        self.epochs = epochs\n",
    "        self.gen_new_tables = gen_new_tables\n",
    "        self.samples_per_minibatch = batch_size\n",
    "        self.batch_size = batch_size\n",
    "        self.max_bp = max_bp\n",
    "        self.is_16S = is_16S\n",
    "        self.seed = seed\n",
    "        self.gen_new_table_frequency = gen_new_table_frequency\n",
    "        self.epochs_since_last_table = 0\n",
    "        self.encoder_target = None\n",
    "        self.encoder_dtype = None\n",
    "        self.encoder_output_type = None\n",
    "        self.sample_ids = None\n",
    "        self.asv_ids = None\n",
    "        if self.tree_path is not None:\n",
    "            self.tree = to_skbio_treenode(parse_newick(open(self.tree_path).read()))\n",
    "            self.postorder_pos = {n.name: i for i, n in enumerate(self.tree.postorder()) if n.is_tip()}\n",
    "        print(\"rarefy table...\")\n",
    "        self.rarefied_table: Table = self.table.subsample(rarefy_depth)\n",
    "        self.size = self.rarefied_table.shape[1]\n",
    "        self.steps_per_epoch = self.size // self.batch_size\n",
    "        self.y_data = self.metadata.loc[self._rarefied_table.ids()]\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.steps_per_epoch\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.batch_size\n",
    "        end = start + self.batch_size\n",
    "        sample_indices = self.sample_indices[start:end]\n",
    "        batch_sample_ids = self.sample_ids[sample_indices]\n",
    "        return self._batch_data(batch_sample_ids)\n",
    "    \n",
    "    def _batch_data(self, batch_sample_ids):\n",
    "        num_unique_asvs, sparse_indices, obs_indices, counts = [], [], [], []\n",
    "        cur_row_indx = 0\n",
    "        for s_id in batch_sample_ids:\n",
    "            sample_data = self.rarefied_table.data(s_id, dense=False).tocoo()\n",
    "            obs_idx, sample_counts = sample_data.row, sample_data.data\n",
    "            # remove zeros\n",
    "            non_zero_mask = sample_counts > 0.0\n",
    "            obs_idx = obs_idx[non_zero_mask]\n",
    "            sample_counts = sample_counts[non_zero_mask]\n",
    "            num_unique_asvs.append(len(obs_idx))\n",
    "            sparse_indices.append(([[cur_row_indx, i] for i in range(len(obs_idx))])[:2])\n",
    "            obs_indices.append(obs_idx[:2])\n",
    "            counts.append(sample_counts[:2])\n",
    "            cur_row_indx += 1\n",
    "        num_unique_asvs = np.array(num_unique_asvs, dtype=np.int32)\n",
    "        sparse_indices = np.vstack(sparse_indices, dtype=np.int32)\n",
    "        obs_indices = np.hstack(obs_indices, dtype=np.int32)\n",
    "        counts = np.hstack(counts, dtype=np.float32)[:, np.newaxis]\n",
    "        \n",
    "        # get list of unique observations in batch\n",
    "        unique_obs, obs_indices = np.unique(obs_indices, return_inverse=True)\n",
    "        obs = self.rarefied_table.ids(axis=\"observation\")\n",
    "        tokens = obs[unique_obs]\n",
    "        y_true = self.y_data.loc[batch_sample_ids].to_numpy()[:, np.newaxis]\n",
    "        # return (tokens, sparse_indices, obs_indices, counts), y_true # [unknown num of unique seq, N]\n",
    "        return self.calc_embedding_mean(tokens, sparse_indices, obs_indices, counts), y_true\n",
    "    \n",
    "    def batch_embeddings(self, asv_embeddings, batch_indicies, counts, asv_indices=None):\n",
    "        emb_dim = tf.shape(asv_embeddings)[-1]\n",
    "        if asv_indices is not None:\n",
    "            asv_embeddings = tf.gather(asv_embeddings, asv_indices)\n",
    "        batch_shape = tf.reduce_max(batch_indicies[:, 0]) + 1\n",
    "        max_unique = tf.reduce_max(batch_indicies[:, 1]) + 1\n",
    "        batch_embeddings = tf.scatter_nd(\n",
    "            batch_indicies, asv_embeddings, shape=[batch_shape, max_unique, emb_dim]\n",
    "        )\n",
    "        counts = tf.scatter_nd(\n",
    "            batch_indicies, counts, shape=[batch_shape, max_unique, 1]\n",
    "        )\n",
    "        return batch_embeddings.numpy(), counts.numpy()\n",
    "\n",
    "    def calc_embedding_mean(self, tokens, sparse_indices, obs_indices, counts):\n",
    "        '''\n",
    "        input: batch_data output\n",
    "        returns: [B, A, E]\n",
    "        '''\n",
    "        # tokens = tokens[:2]\n",
    "        inputs = [self.tokenizer(token, return_tensors = 'pt')[\"input_ids\"].to(device) for token in tokens]\n",
    "        hidden_states = [self.model(input) for input in inputs] # shape: [B x A, N, E]\n",
    "        embedding_mean = [torch.mean(byte_pair, dim=1) for byte_pair, class_token in hidden_states] # embedding with mean pooling\n",
    "        embeddings, counts = self.batch_embeddings(torch.concat(embedding_mean, dim=0).detach().numpy(), sparse_indices, counts, obs_indices) # shape: [num of unique sequences, E]\n",
    "        return embeddings, counts\n",
    "\n",
    "        \n",
    "    def sort_using_counts(self, tensor, counts):\n",
    "        sorted_indices = tf.argsort(tf.squeeze(counts, axis=-1), axis=1, direction=\"DESCENDING\")\n",
    "        sorted_tensor = tf.gather(tensor, sorted_indices, axis=1, batch_dims=1)\n",
    "        sorted_counts = tf.gather(counts, sorted_indices, axis=1, batch_dims=1)\n",
    "        return sorted_tensor, sorted_counts\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.gen_new_tables and self.epochs_since_last_table > self.gen_new_table_frequency:\n",
    "            print(\"resampling dataset...\")\n",
    "            self.rarefied_table = self.table.subsample(self.rarefy_depth)\n",
    "            self.epochs_since_last_table = 0\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.sample_indices)\n",
    "        self.epochs_since_last_table += 1\n",
    "    \n",
    "    @property\n",
    "    def rarefied_table(self):\n",
    "        return self._rarefied_table\n",
    "    \n",
    "    @rarefied_table.setter\n",
    "    def rarefied_table(self, table: Table):\n",
    "        self._rarefied_table = table\n",
    "        print(\"removing empty sample/obs from table\")\n",
    "        self._rarefied_table.remove_empty()\n",
    "        if self.tree_path is not None:\n",
    "            def sort_obs(obs):\n",
    "                post_pos = [self.postorder_pos[ob] for ob in obs]\n",
    "                sorted_indices = np.argsort(post_pos)\n",
    "                return obs[sorted_indices]\n",
    "            self._rarefied_table = self._rarefied_table.sort(sort_obs, axis=\"observation\")\n",
    "        self.sample_ids = self._rarefied_table.ids()\n",
    "        self.asv_ids = self._rarefied_table.ids(axis=\"observation\")\n",
    "        self.sample_indices = np.arange(len(self.sample_ids))\n",
    "        print(\"creating encoder target...\")\n",
    "        self.encoder_target = self._create_encoder_target()\n",
    "        print(\"encoder target created\")\n",
    "\n",
    "    def _create_encoder_target(self) -> None:\n",
    "        return None\n",
    "    \n",
    "    def _encoder_output(self, sample_ids):\n",
    "        return None\n",
    "    \n",
    "    @property\n",
    "    def table(self) -> Table:\n",
    "        return self._table\n",
    "    @table.setter\n",
    "    def table(self, table):\n",
    "        self._table = table\n",
    "    @property\n",
    "    def metadata(self) -> pd.Series:\n",
    "        return self._metadata\n",
    "    @metadata.setter\n",
    "    def metadata(self, metadata):\n",
    "        if metadata is None:\n",
    "            return\n",
    "        if isinstance(metadata, str):\n",
    "            metadata = pd.read_csv(metadata, sep=\"\\t\", index_col=0, dtype={0: str})\n",
    "        if self.metadata_column not in metadata.columns:\n",
    "            raise Exception(f\"Invalid metadata column {self.metadata_column}\")\n",
    "        print(\"aligning table with metadata\")\n",
    "        samp_ids = np.intersect1d(self.table.ids(axis=\"sample\"), metadata.index)\n",
    "        self.table.filter(samp_ids, axis=\"sample\", inplace=True)\n",
    "        self.table.remove_empty()\n",
    "        metadata = metadata.loc[self.table.ids(), self.metadata_column]\n",
    "        print(f\"aligned table shape: {self.table.shape}\")\n",
    "        print(f\"aligned metadata shape: {metadata.shape}\")\n",
    "        metadata = metadata.astype(np.int32)\n",
    "        self._metadata = metadata.reindex(self.table.ids())\n",
    "        print(\"done preprocessing metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning table with metadata\n",
      "aligned table shape: (26778, 269)\n",
      "aligned metadata shape: (269,)\n",
      "done preprocessing metadata\n",
      "rarefy table...\n",
      "removing empty sample/obs from table\n",
      "creating encoder target...\n",
      "encoder target created\n"
     ]
    }
   ],
   "source": [
    "gen = GeneratorDataset(\"data/input/merged_biom_table.biom\", \"data/input/training_metadata.tsv\", \"has_covid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([[[-0.10416535,  0.07718358,  0.07524616, ...,  0.03523894,\n",
       "            0.06350107,  0.11642157],\n",
       "          [-0.06947182,  0.07317469,  0.06933934, ...,  0.04492776,\n",
       "            0.09360398,  0.08222608]],\n",
       "  \n",
       "         [[-0.05706431,  0.04534246,  0.09490667, ..., -0.01283019,\n",
       "            0.04796402,  0.07663572],\n",
       "          [-0.07141566,  0.05508459,  0.02317847, ...,  0.02454554,\n",
       "            0.05045987,  0.14504033]],\n",
       "  \n",
       "         [[-0.08008792,  0.13445865,  0.16800281, ...,  0.03898952,\n",
       "            0.07082699,  0.09655195],\n",
       "          [-0.08790375,  0.12666956,  0.17301773, ...,  0.02596849,\n",
       "            0.06304552,  0.10835315]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[-0.04361127,  0.08778518,  0.0632642 , ..., -0.02247675,\n",
       "            0.10746151,  0.03641083],\n",
       "          [-0.05611859,  0.0719678 ,  0.05996731, ..., -0.01507601,\n",
       "            0.10763866,  0.02790567]],\n",
       "  \n",
       "         [[-0.09910258,  0.09380104,  0.12231942, ..., -0.04979033,\n",
       "            0.05987035,  0.09425615],\n",
       "          [-0.07906005,  0.06717001,  0.09104406, ...,  0.04814729,\n",
       "            0.03664549,  0.10809119]],\n",
       "  \n",
       "         [[-0.08063816,  0.05442476,  0.09946447, ...,  0.0238876 ,\n",
       "            0.09882685,  0.05133961],\n",
       "          [-0.07906005,  0.06717001,  0.09104406, ...,  0.04814729,\n",
       "            0.03664549,  0.10809119]]], dtype=float32),\n",
       "  array([[[1.],\n",
       "          [1.]],\n",
       "  \n",
       "         [[5.],\n",
       "          [3.]],\n",
       "  \n",
       "         [[1.],\n",
       "          [2.]],\n",
       "  \n",
       "         [[1.],\n",
       "          [1.]],\n",
       "  \n",
       "         [[3.],\n",
       "          [1.]],\n",
       "  \n",
       "         [[1.],\n",
       "          [1.]],\n",
       "  \n",
       "         [[1.],\n",
       "          [3.]],\n",
       "  \n",
       "         [[3.],\n",
       "          [2.]]], dtype=float32)),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]], dtype=int32))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding():\n",
    "    '''\n",
    "    output: [B, A, E]\n",
    "    '''\n",
    "    # set device\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "    # initialize tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
    "    config = BertConfig.from_pretrained(\"zhihan1996/DNABERT-2-117M\")\n",
    "    model = AutoModel.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True, config=config).to(device)\n",
    "    model.requires_grad = False\n",
    "    \n",
    "    def batch_embeddings(asv_embeddings, batch_indicies, counts, asv_indices=None):\n",
    "        emb_dim = tf.shape(asv_embeddings)[-1]\n",
    "        if asv_indices is not None:\n",
    "            asv_embeddings = tf.gather(asv_embeddings, asv_indices)\n",
    "        batch_shape = tf.reduce_max(batch_indicies[:, 0]) + 1\n",
    "        max_unique = tf.reduce_max(batch_indicies[:, 1]) + 1\n",
    "        batch_embeddings = tf.scatter_nd(\n",
    "            batch_indicies, asv_embeddings, shape=[batch_shape, max_unique, emb_dim]\n",
    "        )\n",
    "        counts = tf.scatter_nd(\n",
    "            batch_indicies, counts, shape=[batch_shape, max_unique, 1]\n",
    "        )\n",
    "        return batch_embeddings.numpy(), counts.numpy()\n",
    "\n",
    "    def calc_embedding_mean(tokens, sparse_indices, obs_indices, counts):\n",
    "        '''\n",
    "        input: batch_data output\n",
    "        returns: [B, A, E]\n",
    "        '''\n",
    "        # tokens = tokens[:2]\n",
    "        inputs = [tokenizer(token, return_tensors = 'pt')[\"input_ids\"].to(device) for token in tokens]\n",
    "        print(inputs[1].shape)\n",
    "        # inputs = torch.concat(inputs, dim=0).to(device) # [number of unique sequences, N] where N is byte pairs\n",
    "        hidden_states = [model(input) for input in inputs] # shape: [B x A, N, E]\n",
    "        embedding_mean = [torch.mean(byte_pair, dim=1) for byte_pair, class_token in hidden_states] # embedding with mean pooling\n",
    "        embeddings, counts = batch_embeddings(torch.concat(embedding_mean, dim=0).detach().numpy(), sparse_indices, counts, obs_indices) # shape: [num of unique sequences, E]\n",
    "        return embeddings, counts\n",
    "    \n",
    "    return calc_embedding_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 36])\n",
      "tensor([[[-0.0403,  0.0607,  0.1705,  ...,  0.0023,  0.1198,  0.0257],\n",
      "         [-0.0627,  0.0756,  0.0871,  ...,  0.0529,  0.0544,  0.0965]],\n",
      "\n",
      "        [[-0.0791,  0.0672,  0.0910,  ...,  0.0481,  0.0366,  0.1081],\n",
      "         [-0.0714,  0.0551,  0.0232,  ...,  0.0245,  0.0505,  0.1450]],\n",
      "\n",
      "        [[-0.0532,  0.0889,  0.0643,  ..., -0.0142,  0.1133,  0.0303],\n",
      "         [-0.0561,  0.0720,  0.0600,  ..., -0.0151,  0.1076,  0.0279]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0561,  0.0720,  0.0600,  ..., -0.0151,  0.1076,  0.0279],\n",
      "         [-0.0791,  0.0672,  0.0910,  ...,  0.0481,  0.0366,  0.1081]],\n",
      "\n",
      "        [[-0.0727,  0.0544,  0.1143,  ..., -0.0174,  0.1117,  0.1183],\n",
      "         [-0.0626,  0.0481,  0.0178,  ..., -0.0067,  0.1115,  0.1134]],\n",
      "\n",
      "        [[-0.0561,  0.0720,  0.0600,  ..., -0.0151,  0.1076,  0.0279],\n",
      "         [-0.0791,  0.0672,  0.0910,  ...,  0.0481,  0.0366,  0.1081]]])\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = get_embedding()\n",
    "x, y = gen[1]\n",
    "inputs = feature_extractor(*x)\n",
    "print(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "# lt, rt = inputs[1]\n",
    "# print(\"token shape:\", gen[1][0][0].shape)\n",
    "# print(\"lt:\", lt.shape)\n",
    "# print(\"rt:\", rt.shape)\n",
    "print(inputs[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncodingBlock(nn.Module):\n",
    "    def __init__(self, num_attention_heads=4, dropout_rate=0.1, **kwargs): # change num_attention_heads to whatever dnabert 2 uses\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "\n",
    "        emb_dim = 768\n",
    "        key_dim = emb_dim // self.num_attention_heads\n",
    "        self.attention_layer = nn.MultiheadAttention(embed_dim=emb_dim, num_heads=self.num_attention_heads)\n",
    "        self.ffi = nn.Linear(768, 3072)\n",
    "        self.ffo = nn.Linear(3072, 768)\n",
    "        self.activation = nn.GELU()\n",
    "        self.rezero_alpha = nn.Parameter(torch.zeros(1), requires_grad=True)\n",
    "        self.ff_dropout_rate = nn.Dropout(p=self.dropout_rate)\n",
    "        self.attention_dropout = nn.Dropout(p=self.dropout_rate)\n",
    "\n",
    "    def forward(self, input, attention_mask=None, training=False):\n",
    "        \"\"\"\n",
    "        input: [B, A, N]\n",
    "        attention_mask: [B, A, 1]\n",
    "        \"\"\"\n",
    "        # attention\n",
    "        attention_mask = torch.matmul(attention_mask, attention_mask.transpose(-1, -2))\n",
    "        attention_output, _ = self.attention_layer(input, input, input, attn_mask=attention_mask)\n",
    "        \n",
    "        # rezero skip connection\n",
    "        if training:\n",
    "            attention_output = self.attention_dropout(attention_output)\n",
    "        attention_output = input + self.rezero_alpha * attention_output\n",
    "\n",
    "        # feed forward\n",
    "        ffi_output = self.ffi(attention_output)\n",
    "        ffi_activation = self.activation(ffi_output)\n",
    "        ffo_output = self.ffo(ffi_activation)\n",
    "        ffo_activation = self.activation(ffo_output)\n",
    "\n",
    "        # dropout\n",
    "        if training:\n",
    "            ffo_activation = self.ff_dropout_rate(ffo_activation)\n",
    "\n",
    "        return attention_output + self.rezero_alpha * ffo_activation\n",
    "\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, num_attention_layers=4, num_attention_heads=4, dropout_rate=0.1):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.num_attention_layers = num_attention_layers\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.encoding_layers = nn.ModuleList([\n",
    "            TransformerEncodingBlock(self.num_attention_heads, self.dropout_rate) for _ in range(self.num_attention_layers)\n",
    "        ])\n",
    "        self.rezero_alpha = nn.Parameter(torch.zeros(1), requires_grad=True)\n",
    "\n",
    "    def forward(self, inputs, attention_mask=None, training=False):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        output = inputs\n",
    "        for i in range(self.num_attention_layers):\n",
    "            output = self.encoding_layers[i](output, attention_mask=attention_mask, training=training)\n",
    "        \n",
    "        return inputs * self.rezero_alpha + output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_extractor, num_classes=2, **kwargs):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.feature_extractor.requires_grad = False\n",
    "\n",
    "        self.encoder = TransformerEncoder()\n",
    "        self.pooling = lambda x: torch.mean(x, dim=-1)\n",
    "        # self.tokenizer\n",
    "        self.dense_ff = nn.Linear(in_features=516, out_features=1)\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        # Initialize AUC metric\n",
    "        self.auc_metric = AUROC(task=\"binary\", num_classes=num_classes)\n",
    "\n",
    "    def forward(self, inputs, mask=None):\n",
    "        \"\"\"\n",
    "        inputs: [B, A, N] - Batch, ASV, Nucleotides\n",
    "        \"\"\"\n",
    "        features = self.feature_extractor(inputs)  # [B, A, E]\n",
    "\n",
    "        encoding_output = self.encoder(features, attention_mask=mask)  # [B, A, N]\n",
    "        pooling_output = self.pooling(encoding_output)  # [B, N]\n",
    "        logits = self.dense_ff(pooling_output)  \n",
    "        return logits #  classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('data/input/samples_X_test.csv').drop(columns=['sample_name', 'study_sample_type'])[:2]\n",
    "y_test = pd.read_csv('data/input/samples_y_test.csv')[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.float32)\n",
    "y_test_tensor = y_test_tensor.view(-1, 1)\n",
    "y_test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 195/195 [00:11<00:00, 17.31it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 516/516 [00:30<00:00, 16.86it/s]\n",
      "100%|██████████| 2/2 [00:41<00:00, 20.96s/it]\n",
      "100%|██████████| 1/1 [00:43<00:00, 43.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss: 0.6927562952041626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Classifier(get_embedding).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "auc_metric = AUROC(task=\"binary\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "epochs = 1\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "\n",
    "    # forward pass\n",
    "    output = model(X_test)\n",
    "\n",
    "    # compute loss and update metric\n",
    "    loss = criterion(output, y_test_tensor)\n",
    "    auc_metric.update(output, y_test_tensor)\n",
    "\n",
    "    # optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # loss backward\n",
    "    loss.backward()\n",
    "\n",
    "    # optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final AUC: 0.8333333134651184\n"
     ]
    }
   ],
   "source": [
    "final_auc = auc_metric.compute()\n",
    "\n",
    "print(f\"Final AUC: {final_auc.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid_llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
