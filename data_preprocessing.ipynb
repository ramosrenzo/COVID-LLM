{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import biom\n",
    "from biom.util import biom_open\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hospital meta data\n",
    "names_meta_v = [9102, 9159, 9230, 9249]\n",
    "get_file_meta = lambda x: 'data/hospital/sample_information_from_prep_'+str(x)+'.tsv'\n",
    "hospital_meta = pd.concat([pd.read_csv(get_file_meta(i), sep='\\t') for i in names_meta_v]).drop_duplicates()\n",
    "hospital_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge meta data with all biome data \n",
    "hospital_meta = hospital_meta[['sample_name', 'sample_sarscov2_screening_result', 'study_sample_type']]\n",
    "hospital_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query to get relevant rows\n",
    "data = hospital_meta.query(\n",
    "    \"study_sample_type in ['stool', 'forehead', 'inside floor', 'nares'] & \\\n",
    "    sample_sarscov2_screening_result in ['not detected', 'positive']\"\n",
    ").reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microbiome data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge biome tables\n",
    "table1 = biom.load_table(\"data/hospital/150/133520_all.biom\")\n",
    "table2 = biom.load_table(\"data/hospital/150/134073_all.biom\")\n",
    "table3 = biom.load_table(\"data/hospital/150/134769_all.biom\")\n",
    "table4 = biom.load_table(\"data/hospital/150/134858_all.biom\")\n",
    "merged_table = table1.merge(table2).merge(table3).merge(table4)\n",
    "\n",
    "with biom_open('data/input/merged_biom_table.biom', 'w') as f:\n",
    "    merged_table.to_hdf5(f, 'created table')\n",
    "\n",
    "\n",
    "# load table as df\n",
    "merged_table.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X = data.drop(columns=['study_sample_type', 'sample_sarscov2_screening_result'], axis=1)\n",
    "y = data[['study_sample_type', 'sample_sarscov2_screening_result']]\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write txt file  with names of sample used for training\n",
    "with open(\"data/input/training_samples.txt\", \"w\") as f:\n",
    "    for s in X_train['sample_name']:\n",
    "        f.write(f'{s}\\n')\n",
    "#Read the names of each sample into a array\n",
    "with open(\"data/input/training_samples.txt\", \"r\") as f:\n",
    "    samples_train = [s.strip() for s in f.readlines()]\n",
    "\n",
    "#Write txt file  with names of sample used for training\n",
    "with open(\"data/input/test_samples.txt\", \"w\") as f:\n",
    "    for s in X_test['sample_name']:\n",
    "        f.write(f'{s}\\n')\n",
    "\n",
    "#Read the names of each sample into a array\n",
    "with open(\"data/input/test_samples.txt\", \"r\") as f:\n",
    "    samples_test = [s.strip() for s in f.readlines()]\n",
    "\n",
    "def check_covid_positive(row):\n",
    "    if row =='positive':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "# hospital meta data\n",
    "names_meta_v = [9102, 9159, 9230, 9249]\n",
    "get_file_meta = lambda x: 'data/hospital/sample_information_from_prep_'+str(x)+'.tsv'\n",
    "hospital_meta = pd.concat([pd.read_csv(get_file_meta(i), sep='\\t') for i in names_meta_v]).drop_duplicates()\n",
    "hospital_meta['has_covid'] = hospital_meta['sample_sarscov2_screening_result'].apply(check_covid_positive)\n",
    "hospital_meta.head()\n",
    "training_data = hospital_meta.loc[hospital_meta[\"sample_name\"].isin(samples_train)]\n",
    "test_data = hospital_meta.loc[hospital_meta[\"sample_name\"].isin(samples_test)]\n",
    "\n",
    "#save training metadata to tsv\n",
    "training_data.to_csv(\"data/input/training_metadata.tsv\", sep=\"\\t\", index=False)\n",
    "test_data.to_csv(\"data/input/test_metadata.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to csv\n",
    "X_train.assign(study_sample_type=y_train['study_sample_type']).reset_index(drop=True).to_csv('data/input/samples_X_train.csv', index=False, sep='\\t')\n",
    "X_test.assign(study_sample_type=y_test['study_sample_type']).reset_index(drop=True).to_csv('data/input/samples_X_test.csv', index=False, sep='\\t')\n",
    "y_train.drop(columns=['study_sample_type']).reset_index(drop=True).to_csv('data/input/samples_y_train.csv', index=False, sep='\\t')\n",
    "y_test.drop(columns=['study_sample_type']).reset_index(drop=True).to_csv('data/input/samples_y_test.csv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train metadata per sample environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metadata = pd.read_csv('data/input/training_metadata.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metadata_inside_floor = training_metadata[training_metadata['study_sample_type'] == 'inside floor']\n",
    "training_metadata_forehead = training_metadata[training_metadata['study_sample_type'] == 'forehead']\n",
    "training_metadata_stool = training_metadata[training_metadata['study_sample_type'] == 'stool']\n",
    "training_metadata_nares = training_metadata[training_metadata['study_sample_type'] == 'nares']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_metadata_inside_floor.shape, training_metadata_forehead.shape, training_metadata_stool.shape, training_metadata_inside_floor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metadata_inside_floor.to_csv(\"data/input/training_metadata_inside_floor.tsv\", sep=\"\\t\", index=False)\n",
    "training_metadata_forehead.to_csv(\"data/input/training_metadata_forehead.tsv\", sep=\"\\t\", index=False)\n",
    "training_metadata_stool.to_csv(\"data/input/training_metadata_stool.tsv\", sep=\"\\t\", index=False)\n",
    "training_metadata_nares.to_csv(\"data/input/training_metadata_nares.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test metadata per sample environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata = pd.read_csv('data/input/test_metadata.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata_inside_floor = test_metadata[test_metadata['study_sample_type'] == 'inside floor']\n",
    "test_metadata_forehead = test_metadata[test_metadata['study_sample_type'] == 'forehead']\n",
    "test_metadata_stool = test_metadata[test_metadata['study_sample_type'] == 'stool']\n",
    "test_metadata_nares = test_metadata[test_metadata['study_sample_type'] == 'nares']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_metadata_inside_floor.shape, test_metadata_forehead.shape, test_metadata_stool.shape, test_metadata_nares.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata_inside_floor.to_csv(\"data/input/test_metadata_inside_floor.tsv\", sep=\"\\t\", index=False)\n",
    "test_metadata_forehead.to_csv(\"data/input/test_metadata_forehead.tsv\", sep=\"\\t\", index=False)\n",
    "test_metadata_stool.to_csv(\"data/input/test_metadata_stool.tsv\", sep=\"\\t\", index=False)\n",
    "test_metadata_nares.to_csv(\"data/input/test_metadata_nares.tsv\", sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid_llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
