{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0a8f6d7-ec61-40c1-81dd-42870a45d347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 16:50:39.269675: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-29 16:50:39.269724: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-29 16:50:39.269754: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-29 16:50:39.279993: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from aam.data_handlers.generator_dataset import GeneratorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a3a2367-6c9b-4ad2-b3c5-d2b3c6257429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a1620f-2151-41a3-ac03-54d95157b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "# if len(gpus) > 0:\n",
    "#     tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "# gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e9a9e27-1904-4647-9db3-a69670ce3a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3061/4195698998.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fecal_filtered['has_covid'] = fecal_filtered['covid_positive'].apply(check_covid_positive)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>covid_positive</th>\n",
       "      <th>has_covid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14812.N.066</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.N.051</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.N.068</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.N.037</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV10.R025</th>\n",
       "      <td>recovered</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19.R069</th>\n",
       "      <td>recovered</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19.R071</th>\n",
       "      <td>recovered</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV19.R.022</th>\n",
       "      <td>recovered</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19.R078</th>\n",
       "      <td>recovered</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV19.004</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV19.008</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV19.R034</th>\n",
       "      <td>recovered</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV19.002</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.N.035</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19.079</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19.R074</th>\n",
       "      <td>recovered</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19.048</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.N.026</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19.R082</th>\n",
       "      <td>recovered</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.N.061</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.N.013</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19.R054</th>\n",
       "      <td>recovered</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19.046</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV19.R.003.1</th>\n",
       "      <td>recovered</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV19.R.020</th>\n",
       "      <td>recovered</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19.042</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19.011</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19.047</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19.R083</th>\n",
       "      <td>recovered</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.N.038</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.N.016</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV19.007</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV19.012</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV19.006</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV19.R.027</th>\n",
       "      <td>recovered</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV19.R040</th>\n",
       "      <td>recovered</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19.R081</th>\n",
       "      <td>recovered</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV19.005</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.N.032</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19.043</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.N.072</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.N.015</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19.R057</th>\n",
       "      <td>recovered</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.N.014</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.N.062</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV19.001</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19.080</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19R036</th>\n",
       "      <td>recovered</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19.R024</th>\n",
       "      <td>recovered</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.N.060</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19.010</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.N.065</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19.R077</th>\n",
       "      <td>recovered</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19.R084</th>\n",
       "      <td>recovered</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19.041</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.N.070</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.N.055</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19.086</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.CV.19.009</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812.N.073</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   covid_positive  has_covid\n",
       "sample_name                                 \n",
       "14812.N.066                    no          0\n",
       "14812.N.051                    no          0\n",
       "14812.N.068                    no          0\n",
       "14812.N.037                    no          0\n",
       "14812.CV10.R025         recovered          0\n",
       "14812.CV.19.R069        recovered          0\n",
       "14812.CV.19.R071        recovered          0\n",
       "14812.CV19.R.022        recovered          0\n",
       "14812.CV.19.R078        recovered          0\n",
       "14812.CV19.004                yes          1\n",
       "14812.CV19.008                yes          1\n",
       "14812.CV19.R034         recovered          0\n",
       "14812.CV19.002                yes          1\n",
       "14812.N.035                    no          0\n",
       "14812.CV.19.079               yes          1\n",
       "14812.CV.19.R074        recovered          0\n",
       "14812.CV.19.048               yes          1\n",
       "14812.N.026                    no          0\n",
       "14812.CV.19.R082        recovered          0\n",
       "14812.N.061                    no          0\n",
       "14812.N.013                    no          0\n",
       "14812.CV.19.R054        recovered          0\n",
       "14812.CV.19.046               yes          1\n",
       "14812.CV19.R.003.1      recovered          0\n",
       "14812.CV19.R.020        recovered          0\n",
       "14812.CV.19.042               yes          1\n",
       "14812.CV.19.011               yes          1\n",
       "14812.CV.19.047               yes          1\n",
       "14812.CV.19.R083        recovered          0\n",
       "14812.N.038                    no          0\n",
       "14812.N.016                    no          0\n",
       "14812.CV19.007                yes          1\n",
       "14812.CV19.012                yes          1\n",
       "14812.CV19.006                yes          1\n",
       "14812.CV19.R.027        recovered          0\n",
       "14812.CV19.R040         recovered          0\n",
       "14812.CV.19.R081        recovered          0\n",
       "14812.CV19.005                yes          1\n",
       "14812.N.032                    no          0\n",
       "14812.CV.19.043               yes          1\n",
       "14812.N.072                    no          0\n",
       "14812.N.015                    no          0\n",
       "14812.CV.19.R057        recovered          0\n",
       "14812.N.014                    no          0\n",
       "14812.N.062                    no          0\n",
       "14812.CV19.001                yes          1\n",
       "14812.CV.19.080               yes          1\n",
       "14812.CV.19R036         recovered          0\n",
       "14812.CV.19.R024        recovered          0\n",
       "14812.N.060                    no          0\n",
       "14812.CV.19.010               yes          1\n",
       "14812.N.065                    no          0\n",
       "14812.CV.19.R077        recovered          0\n",
       "14812.CV.19.R084        recovered          0\n",
       "14812.CV.19.041               yes          1\n",
       "14812.N.070                    no          0\n",
       "14812.N.055                    no          0\n",
       "14812.CV.19.086               yes          1\n",
       "14812.CV.19.009               yes          1\n",
       "14812.N.073                    no          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fecal = pd.read_csv('fecal.tsv', sep='\\t')\n",
    "\n",
    "fecal_filtered = fecal[['sample_name', 'covid_positive']]\n",
    "\n",
    "fecal_filtered\n",
    "\n",
    "def check_covid_positive(row):\n",
    "    if row =='yes':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "fecal_filtered['has_covid'] = fecal_filtered['covid_positive'].apply(check_covid_positive)\n",
    "fecal_filtered.set_index('sample_name', inplace=True)\n",
    "fecal_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "624bf78b-b4d4-417a-8d09-9d7b02fb6f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class ASVWrapper(tf.keras.layers.Layer):\n",
    "    def __init__(self, asv_encoder, **kwargs):\n",
    "        super(ASVWrapper, self).__init__(**kwargs)\n",
    "        self.asv_encoder = asv_encoder\n",
    "        self.asv_encoder.trainable = False\n",
    "        self.embedding_dim = self.asv_encoder.embedding_dim\n",
    "    def call(self, inputs, training=False):\n",
    "        embeddings, counts = self.asv_encoder(inputs, return_asv_embeddings=True, training=False)\n",
    "        return embeddings, counts\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"asv_encoder\": tf.keras.saving.serialize_keras_object(self.asv_encoder)})\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        config[\"asv_encoder\"] = tf.keras.saving.deserialize_keras_object(config[\"asv_encoder\"])\n",
    "        model = cls(**config)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e39f7d8a-8759-424c-8412-d8d5d41625d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(gen):\n",
    "    enqueuer = tf.keras.utils.OrderedEnqueuer(gen, use_multiprocessing=True)\n",
    "    enqueuer.start(workers=2, max_queue_size=gen.steps_per_epoch)\n",
    "    gen.stop = lambda: enqueuer.stop(0.1)\n",
    "    y_type = tf.TensorSpec(shape=(gen.samples_per_minibatch, 1), dtype=tf.string)\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        enqueuer.get,\n",
    "        output_signature=(\n",
    "            (\n",
    "                tf.TensorSpec(shape=[None, 150], dtype=tf.int32),\n",
    "                tf.TensorSpec(shape=[None, 2], dtype=tf.int32),\n",
    "                tf.TensorSpec(shape=[None], dtype=tf.int32),\n",
    "                tf.TensorSpec(shape=[None, 1], dtype=tf.int32),\n",
    "            ),\n",
    "            tf.TensorSpec(shape=(None, 1), dtype=tf.int32),\n",
    "        ),\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d6aedf7-b2dc-4399-882a-bb2d0fcdbce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning table with metadata\n",
      "aligned table shape: (7969, 60)\n",
      "aligned metadata shape: (60,)\n",
      "done preprocessing metadata\n",
      "rarefy table...\n",
      "removing empty sample/obs from table\n",
      "creating encoder target...\n",
      "encoder target created\n"
     ]
    }
   ],
   "source": [
    "gd = GeneratorDataset(\n",
    "    table='/home/swchan/DSC170/fecal.biom',\n",
    "    metadata=fecal_filtered,\n",
    "    metadata_column='has_covid',\n",
    "    shuffle=False,\n",
    "    is_categorical=False,\n",
    "    shift=0,\n",
    "    scale=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15b4ca4e-3a0e-4354-a4ff-1b0904d1bffb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1205, 150), (1845, 2), (1845,), (1845, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = gd[0]\n",
    "print(y.shape)\n",
    "a, b, c, d = x\n",
    "a.shape, b.shape, c.shape, d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d90e8c5-a0ef-4b82-bbbb-89b33eb0a335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 16:50:43.981272: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9833c810-9909-401e-bda8-51bd884e7bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from biom import load_table\n",
    "# df = \"\"\n",
    "\n",
    "# df[\"covid_positive\"]\n",
    "\n",
    "# table = load_table(\"fecal.biom\")\n",
    "# df = df.sort_index(table.ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "861a57f0-d464-478f-ab7d-6f709603cb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# model = tf.keras.models.load_model('/home/swchan/DSC170/model.keras', compile=False)\n",
    "# model = ASVWrapper(model)\n",
    "\n",
    "# @tf.function(reduce_retracing=True)\n",
    "# def call_step(inputs):\n",
    "#     return model(inputs)\n",
    "                 \n",
    "# for x, y in dataset.take(gd.steps_per_epoch):\n",
    "#     embeddings, counts = call_step(x)\n",
    "#     attention_mask = tf.cast(counts  >  0, dtype=tf.float32)\n",
    "#     attention_mask = tf.matmul(attention_mask, attention_mask, transpose_b=True)\n",
    "#     print(\"k\")\n",
    "# gd.stop()\n",
    "\n",
    "#Output B x A x E Tensor (Sample Number x ASVs x Embedding Dimension)\n",
    "# B x A x E Tensor (Sample Number x ASVs x 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24f0f399-ab64-47e0-92a1-d425d2a06cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swchan/.conda/envs/aam/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing ASVEncoder...\n",
      "create asv layer with 8 heads\n",
      "Using linear bias\n",
      "Encoder residual connection...\n",
      "Encoder exit... True\n",
      "ASVEncoder exit... True\n",
      "Using linear bias\n",
      "Pooler residual connection...\n",
      "Pooler exit... True\n",
      "BaseSequenceEncoder exit... True\n",
      "Constructing UnifracDenoser from config\n",
      "Encoder residual connection...\n",
      "Encoder exit... False\n",
      "ASVEncoder exit... False\n",
      "Pooler residual connection...\n",
      "Pooler exit... False\n",
      "BaseSequenceEncoder exit... False\n",
      "Input Shape in build: (None, None, 128)\n",
      "Using linear bias\n",
      "Encoder residual connection...\n",
      "Encoder exit... True\n",
      "Using linear bias\n",
      "Pooler residual connection...\n",
      "Pooler exit... True\n",
      "UnifracEncoder exit... True\n",
      "Input Shape in build: (None, None, 128)\n",
      "Using linear bias\n",
      "Encoder residual connection...\n",
      "Encoder exit... True\n",
      "Using linear bias\n",
      "Pooler residual connection...\n",
      "Pooler exit... True\n",
      "UnifracEncoder exit... True\n",
      "UniFracDenoiser exit... True\n",
      "UnifracDenoiser is already built\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "base_model = tf.keras.models.load_model('/home/swchan/DSC170/model.keras', compile=False)\n",
    "base_model = ASVWrapper(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "576fe3bc-5f7d-48bf-aa65-18c5a7c965a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = gd[0]\n",
    "# embeddings, count = base_model(x)\n",
    "#Output B x A x E Tensor (Sample Number x ASVs x Embedding Dimension)\n",
    "# B x A x E Tensor (Sample Number x ASVs x 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73031e43-0f42-479a-a038-759187a045c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e039e2c5-5995-4de8-bf31-d1dc449cd29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TransformerEncodingBlock(K.layers.Layer):\n",
    "#     def __init__(self, num_attention_heads=4, dropout_rate=0.1, **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "#         self.num_attention_heads = num_attention_heads\n",
    "#         self.dropout_rate = dropout_rate\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         emb_dim = input_shape[-1]\n",
    "#         key_dim = emb_  adim // self.num_attention_heads\n",
    "#         self.attention_layer = K.layers.MultiHeadAttention(self.num_attention_heads, key_dim=key_dim, dropout=self.dropout_rate)\n",
    "#         self.attention_layer._build_from_signature(input_shape, input_shape)\n",
    "#         linear_bias = LinearBiasSoftmax()\n",
    "#         setattr(self.attention_layer, 'softmax', linear_bias)\n",
    "        \n",
    "#         self.ff_inner = K.layers.Dense(512, activation=\"gelu\")\n",
    "#         self.ff = K.layers.Dense(emb_dim, activation=\"gelu\")\n",
    "#         self.rezero_alpha = self.add_weight(\"rezero_alpha\", 1, dtype=\"float32\", initializer=\"zero\", trainable=True)\n",
    "\n",
    "#     def call(self, input, attention_mask=None, training=False):\n",
    "#         \"\"\"\n",
    "#         input: [B, A, N] float\n",
    "#         attention_mask: [B, A, 1] bool\n",
    "#         \"\"\"\n",
    "#         # attention\n",
    "#         attention_mask = tf.matmul(attention_mask, attention_mask, transpose_b=True)  # [B, A, A]\n",
    "#         attention_output = self.attention_layer(input, input, attention_mask=attention_mask, training=training)\n",
    "\n",
    "#         # rezero skip connection\n",
    "#         attention_output = input + self.rezero_alpha * attention_output\n",
    "\n",
    "#         ff_output = self.ff_inner(attention_output)\n",
    "#         ff_output = self.ff(ff_output)\n",
    "\n",
    "#         # rezero skip connection\n",
    "#         ff_output = attention_output + self.rezero_alpha * ff_output\n",
    "\n",
    "#         return ff_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46dd242d-4b3e-484c-8d09-8aef51c6807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TransformerEncoder(K.layers.Layer):\n",
    "#     def __init__(self, num_attention_layers=4, num_attention_heads=4, dropout_rate=0.1, **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "#         self.num_attention_layers = num_attention_layers\n",
    "#         self.num_attention_heads = num_attention_heads\n",
    "#         self.dropout_rate = dropout_rate\n",
    "\n",
    "#         self.encoding_layers = [\n",
    "#             TransformerEncodingBlock(self.num_attention_heads, self.dropout_rate) for _ in range(self.num_attention_layers)\n",
    "#         ]\n",
    "#         self.rezero_alpha = self.add_weight(\"rezero_alpha\", 1, dtype=\"float32\", initializer=\"zero\", trainable=True)\n",
    "\n",
    "#     def call(self, inputs, attention_mask=None, training=False):\n",
    "#         output = inputs\n",
    "#         for i in range(self.num_attention_layers):\n",
    "#             output = self.encoding_layers[i](output, attention_mask=attention_mask, training=training)\n",
    "#         return inputs * self.rezero_alpha * output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d3c17c8-5d02-48cd-854d-5c06b94eefa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "K=tf.keras\n",
    "from aam.models.transformers import TransformerEncoder\n",
    "from aam.models.multihead_attention_pooling import MultiHeadAttentionPooling\n",
    "class Classifier(K.Model):\n",
    "    def __init__(self, feature_extractor, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.feature_extractor.trainable = False\n",
    "\n",
    "        self.encoder = TransformerEncoder(\n",
    "            num_layers=4, \n",
    "            num_attention_heads=4, \n",
    "            intermediate_size=512, \n",
    "            dropout_rate=0.1, \n",
    "            normalize_outputs=False,\n",
    "            use_residual_connections=True,\n",
    "            use_linear_bias=False\n",
    "        )  # transformer (or anything else)\n",
    "        self.pooling = MultiHeadAttentionPooling(normalize_output=False,  use_linear_bias=False)  # extracts sample embeddings from our ASV embeddings\n",
    "        self.dense_ff = K.layers.Dense(1)  # sample_embedings => classifys covid +/-\n",
    "\n",
    "        self.loss_fn = K.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "        self.auc_tracker = K.metrics.Mean()\n",
    "        self.loss_tracker = K.metrics.Mean()\n",
    "\n",
    "    def call(self, inputs, mask=None, training=False):\n",
    "        \"\"\"\n",
    "        inputs: [B, A, N], B: batch_dim, A: # ASV in sample, N: nuctides,\n",
    "        string tensor\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # aam case\n",
    "        features, counts = self.feature_extractor(inputs)\n",
    "        mask =  tf.cast(counts >  0, dtype=\"float32\")\n",
    "\n",
    "        encodig_output = self.encoder(features, mask=mask, training=training)  # [B, A, N]\n",
    "        pooling_output = self.pooling(encodig_output, mask=mask, training=training)  # [B, N]\n",
    "        return self.dense_ff(pooling_output)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "\n",
    "        # create attention mask\n",
    "        # example [[\"ACTG\"], [\"\"]]\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = self(x, training=True)\n",
    "            loss = self.loss_fn(y, output)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.auc_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result(), \"auc\": self.auc_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        output = self(x, training=False)\n",
    "        loss = self.loss_fn(y, output)\n",
    "\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.auc_tracker.update_state(loss)\n",
    "\n",
    "        return {\"loss\": self.loss_tracker.result(), \"auc\": self.auc_tracker.result()}\n",
    "\n",
    "    def predict_step(self, data):\n",
    "        x, y = data\n",
    "        return self(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7bb8a09-3b8a-4074-acab-fbdf84cb7b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier(base_model)\n",
    "\n",
    "optimizer = K.optimizers.Adam(\n",
    "    learning_rate=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd1256c9-8a69-47a9-94a1-f6d3c401d1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder residual connection...\n",
      "Encoder exit... False\n",
      "ASVEncoder exit... False\n",
      "Pooler residual connection...\n",
      "Pooler exit... False\n",
      "BaseSequenceEncoder exit... False\n",
      "Encoder residual connection...\n",
      "Encoder exit... False\n",
      "Pooler residual connection...\n",
      "Pooler exit... False\n",
      "UnifracEncoder exit... False\n",
      "Encoder residual connection...\n",
      "Encoder exit... False\n",
      "Pooler residual connection...\n",
      "Pooler exit... False\n",
      "UnifracEncoder exit... False\n",
      "UniFracDenoiser exit... False\n",
      "Using linear bias\n",
      "Encoder residual connection...\n",
      "Encoder exit... True\n",
      "Pooler residual connection...\n",
      "Pooler exit... True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n",
       "array([[-0.10795963],\n",
       "       [ 0.06111354],\n",
       "       [-0.10168678],\n",
       "       [-0.18776545],\n",
       "       [-0.03257203],\n",
       "       [-0.24220324],\n",
       "       [ 0.06716362],\n",
       "       [-0.1405243 ]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = gd[0]\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a15b374-3289-4fb3-aa94-35aa226ed930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d862f19f-de66-4020-9f73-f49b53dca5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.build([None, None, 1])\n",
    "model.compile(optimizer=optimizer, run_eagerly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47ba94c1-3599-4905-90ae-a9471a44657b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder residual connection...\n",
      "Encoder exit... False\n",
      "ASVEncoder exit... False\n",
      "Pooler residual connection...\n",
      "Pooler exit... False\n",
      "BaseSequenceEncoder exit... False\n",
      "Encoder residual connection...\n",
      "Encoder exit... False\n",
      "Pooler residual connection...\n",
      "Pooler exit... False\n",
      "UnifracEncoder exit... False\n",
      "Encoder residual connection...\n",
      "Encoder exit... False\n",
      "Pooler residual connection...\n",
      "Pooler exit... False\n",
      "UnifracEncoder exit... False\n",
      "UniFracDenoiser exit... False\n",
      "Encoder residual connection...\n",
      "Encoder exit... True\n",
      "Pooler residual connection...\n",
      "Pooler exit... True\n",
      "Encoder residual connection...\n",
      "Encoder exit... False\n",
      "ASVEncoder exit... False\n",
      "Pooler residual connection...\n",
      "Pooler exit... False\n",
      "BaseSequenceEncoder exit... False\n",
      "Encoder residual connection...\n",
      "Encoder exit... False\n",
      "Pooler residual connection...\n",
      "Pooler exit... False\n",
      "UnifracEncoder exit... False\n",
      "Encoder residual connection...\n",
      "Encoder exit... False\n",
      "Pooler residual connection...\n",
      "Pooler exit... False\n",
      "UnifracEncoder exit... False\n",
      "UniFracDenoiser exit... False\n",
      "Encoder residual connection...\n",
      "Encoder exit... True\n",
      "Pooler residual connection...\n",
      "Pooler exit... True\n",
      "2/2 [==============================] - 95s 40s/step - loss: 0.6980 - auc: 0.6993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fb7dcecd820>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# core_callbacks = [\n",
    "#     tf.keras.callbacks.EarlyStopping(\n",
    "#         \"val_loss\",\n",
    "#         patience=25,\n",
    "#         start_from_epoch=25\n",
    "#     )\n",
    "]\n",
    "model.fit(dataset, epochs=1, steps_per_epoch=gd.steps_per_epoch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81e7a054-2c8b-46f1-bb97-be496d07be43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ASVWrapper\" in str(type(base_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b53d627-3564-439f-a436-50e8fbd5cac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test, Train, Valid Sets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aam",
   "language": "python",
   "name": "aam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
