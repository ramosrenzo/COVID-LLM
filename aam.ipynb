{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0a8f6d7-ec61-40c1-81dd-42870a45d347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-24 17:01:40.845234: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-24 17:01:40.845359: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-24 17:01:40.849615: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-24 17:01:41.617955: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/swchan/.conda/envs/aam/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from aam.data_handlers.generator_dataset import GeneratorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "624bf78b-b4d4-417a-8d09-9d7b02fb6f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class ASVWrapper(tf.keras.layers.Layer):\n",
    "    def __init__(self, asv_encoder, **kwargs):\n",
    "        super(ASVWrapper, self).__init__(**kwargs)\n",
    "        self.asv_encoder = asv_encoder\n",
    "        self.asv_encoder.trainable = False\n",
    "        self.embedding_dim = self.asv_encoder.embedding_dim\n",
    "    def _batch_embeddings(self, asv_embeddings, batch_indicies, counts):\n",
    "        batch_shape = tf.reduce_max(batch_indicies[:, 0]) + 1\n",
    "        max_unique = tf.reduce_max(batch_indicies[:, 1]) + 1\n",
    "        batch_embeddings = tf.scatter_nd(batch_indicies, asv_embeddings, shape=[batch_shape, max_unique, self.embedding_dim])\n",
    "        counts = tf.scatter_nd(batch_indicies, counts, shape=[batch_shape, max_unique, 1])\n",
    "        return batch_embeddings, counts\n",
    "    def call(self, inputs, training=False):\n",
    "        tokens, batch_indicies, asv_indicies, counts = inputs\n",
    "        batch_indicies = tf.cast(batch_indicies, dtype=tf.int32)\n",
    "        asv_indicies = tf.cast(asv_indicies, dtype=tf.int32)\n",
    "        asv_embeddings = self.asv_encoder(tokens, training=training)\n",
    "        asv_embeddings = tf.gather(asv_embeddings, asv_indicies)\n",
    "        return self._batch_embeddings(asv_embeddings, batch_indicies, counts)\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"asv_encoder\": tf.keras.saving.serialize_keras_object(self.asv_encoder)})\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        config[\"asv_encoder\"] = tf.keras.saving.deserialize_keras_object(config[\"asv_encoder\"])\n",
    "        model = cls(**config)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e39f7d8a-8759-424c-8412-d8d5d41625d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(gen):\n",
    "    enqueuer = tf.keras.utils.OrderedEnqueuer(gen, use_multiprocessing=True)\n",
    "    enqueuer.start(workers=2, max_queue_size=gen.steps_per_epoch)\n",
    "    gen.stop = lambda: enqueuer.stop(0.1)\n",
    "    y_type = tf.TensorSpec(shape=(gen.samples_per_minibatch, 1), dtype=tf.string)\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        enqueuer.get,\n",
    "        output_signature=(\n",
    "            (\n",
    "                tf.TensorSpec(shape=[None, 150], dtype=tf.int32),\n",
    "                tf.TensorSpec(shape=[None, 2], dtype=tf.int32),\n",
    "                tf.TensorSpec(shape=[None], dtype=tf.int32),\n",
    "                tf.TensorSpec(shape=[None, 1], dtype=tf.int32),\n",
    "            ),\n",
    "            tf.TensorSpec(shape=(gen.batch_size, 1), dtype=tf.string),\n",
    "        ),\n",
    "    )\n",
    "    dataset = dataset.prefetch(10)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d6aedf7-b2dc-4399-882a-bb2d0fcdbce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unrarefied table shape: (7969, 60)\n",
      "metadata shape: (60,)\n"
     ]
    }
   ],
   "source": [
    "gd = GeneratorDataset(\n",
    "    table='/home/swchan/DSC170/fecal.biom',\n",
    "    metadata='/home/swchan/DSC170/fecal.tsv',\n",
    "    metadata_column='covid_positive',\n",
    "    shuffle=False,\n",
    "    is_categorical=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d90e8c5-a0ef-4b82-bbbb-89b33eb0a335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-24 17:02:06.637213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10534 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:86:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9833c810-9909-401e-bda8-51bd884e7bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from biom import load_table\n",
    "# df = \"\"\n",
    "\n",
    "# df[\"covid_positive\"]\n",
    "\n",
    "# table = load_table(\"fecal.biom\")\n",
    "# df = df.sort_index(table.ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "861a57f0-d464-478f-ab7d-6f709603cb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# model = tf.keras.models.load_model('/home/swchan/DSC170/model.keras', compile=False)\n",
    "# model = ASVWrapper(model)\n",
    "\n",
    "# @tf.function(reduce_retracing=True)\n",
    "# def call_step(inputs):\n",
    "#     return model(inputs)\n",
    "                 \n",
    "# for x, y in dataset.take(gd.steps_per_epoch):\n",
    "#     embeddings, counts = call_step(x)\n",
    "#     attention_mask = tf.cast(counts  >  0, dtype=tf.float32)\n",
    "#     attention_mask = tf.matmul(attention_mask, attention_mask, transpose_b=True)\n",
    "#     print(\"k\")\n",
    "# gd.stop()\n",
    "\n",
    "#Output B x A x E Tensor (Sample Number x ASVs x Embedding Dimension)\n",
    "# B x A x E Tensor (Sample Number x ASVs x 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24f0f399-ab64-47e0-92a1-d425d2a06cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create asv layer with 8 heads\n",
      "Encoder residual connection...\n",
      "Encoder exit... True\n",
      "ASVEncoder exit... True\n",
      "Pooler residual connection...\n",
      "Pooler exit... True\n",
      "BaseSequenceEncoder exit... True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "base_model = tf.keras.models.load_model('/home/swchan/DSC170/model.keras', compile=False)\n",
    "base_model = ASVWrapper(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73031e43-0f42-479a-a038-759187a045c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e039e2c5-5995-4de8-bf31-d1dc449cd29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncodingBlock(K.layers.Layer):\n",
    "    def __init__(self, num_attention_heads=4, dropout_rate=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        emb_dim = input_shape[-1]\n",
    "        key_dim = emb_dim // self.num_attention_heads\n",
    "        self.attention_layer = K.layers.MultiHeadAttention(self.num_attention_heads, key_dim=key_dim, dropout=self.dropout_rate)\n",
    "        self.ff = K.layers.Dense(emb_dim)\n",
    "        self.rezero_alpha = self.add_weight(\"rezero_alpha\", 1, dtype=\"float32\", initializer=\"zero\", trainable=True)\n",
    "\n",
    "    def call(self, input, attention_mask=None, training=False):\n",
    "        \"\"\"\n",
    "        input: [B, A, N] float\n",
    "        attention_mask: [B, A, 1] bool\n",
    "        \"\"\"\n",
    "        # attention\n",
    "        attention_mask = tf.matmul(attention_mask, attention_mask, transpose_b=True)  # [B, A, A]\n",
    "        attention_output = self.attention_layer(input, input, attention_mask=attention_mask, training=training)\n",
    "\n",
    "        # rezero skip connection\n",
    "        attention_output = input + self.rezero_alpha * attention_output\n",
    "\n",
    "        ff_output = self.ff(attention_output)\n",
    "\n",
    "        return attention_output + self.rezero_alpha * ff_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46dd242d-4b3e-484c-8d09-8aef51c6807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(K.layers.Layer):\n",
    "    def __init__(self, num_attention_layers=4, num_attention_heads=4, dropout_rate=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_attention_layers = num_attention_layers\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.encoding_layers = [\n",
    "            TransformerEncodingBlock(self.num_attention_heads, self.dropout_rate) for _ in range(self.num_attention_layers)\n",
    "        ]\n",
    "        self.rezero_alpha = self.add_weight(\"rezero_alpha\", 1, dtype=\"float32\", initializer=\"zero\", trainable=True)\n",
    "\n",
    "    def call(self, inputs, attention_mask=None, training=False):\n",
    "        output = inputs\n",
    "        for i in range(self.num_attention_layers):\n",
    "            output = self.encoding_layers[i](output, attention_mask=attention_mask, training=training)\n",
    "        return inputs * self.rezero_alpha * output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d3c17c8-5d02-48cd-854d-5c06b94eefa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "K=tf.keras\n",
    "class Classifier(K.Model):\n",
    "    def __init__(self, feature_extractor, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.feature_extractor.trainable = False\n",
    "\n",
    "        self.encoder = TransformerEncoder()  # transformer (or anything else)\n",
    "        self.pooling = lambda input: K.backend.mean(input, axis=-1)  # extracts sample embeddings from our ASV embeddings\n",
    "        self.tokenizer = K.layers.TextVectorization(4, split=\"character\", pad_to_max_tokens=True)\n",
    "        self.dense_ff = K.layers.Dense(2, activation=\"softmax\")  # sample_embedings => classifys covid +/-\n",
    "\n",
    "        self.loss = K.losses.BinaryCrossentropy()\n",
    "\n",
    "        self.auc_metric = K.metrics.AUC()\n",
    "        self.loss_tracker = K.metrics.Mean()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        pass\n",
    "\n",
    "    def call(self, inputs, mask=None, training=False):\n",
    "        \"\"\"\n",
    "        inputs: [B, A, N], B: batch_dim, A: # ASV in sample, N: nuctides,\n",
    "        string tensor\n",
    "        \"\"\"\n",
    "        features = self.feature_extractor(inputs)  # [B, A, N, E], will probably be different for all models\n",
    "\n",
    "        # some addional processing\n",
    "        if isinstance(self.feature_extractor, \"DNABert\"):\n",
    "            # do something\n",
    "            features = self._extract_asv_embeddings_from_bert(features)\n",
    "            pass\n",
    "        elif isinstance(self.feature_extractor, \"Grove\"):\n",
    "            # do something else\n",
    "            features = self._extract_asv_embeddings_from_grover(features)\n",
    "            pass\n",
    "        else:\n",
    "            # aam case\n",
    "            features = self._extract_asv_embeddings_from_aam(features)\n",
    "            pass\n",
    "\n",
    "        encodig_output = self.encoder(features, attention_mask=mask, training=training)  # [B, A, N]\n",
    "        pooling_output = self.pooling(encodig_output)  # [B, N]\n",
    "        return self.dense_ff(pooling_output)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "\n",
    "        # create attention mask\n",
    "        # example [[\"ACTG\"], [\"\"]]\n",
    "        mask = K.backend.cast(K.backend.sum(self.tokenizer(x), axis=-1) == 0, dtype=\"float32\")\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = self(x, mask=mask, training=True)\n",
    "            loss = self.loss(y, output)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.auc_tracker.update_state(y, output)\n",
    "        return {\"loss\": self.loss_tracker.result(), \"auc\": self.auc_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "\n",
    "        mask = K.backend.cast(K.backend.sum(self.tokenizer(x), axis=-1) == 0, dtype=\"float32\")\n",
    "        output = self(x, mask=mask, training=False)\n",
    "        loss = self.loss(y, output)\n",
    "\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.auc_tracker.update_state(y, output)\n",
    "\n",
    "        return {\"loss\": self.loss_tracker.result(), \"auc\": self.auc_tracker.result()}\n",
    "\n",
    "    def predict_step(self, data):\n",
    "        x, y = data\n",
    "        return self(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7bb8a09-3b8a-4074-acab-fbdf84cb7b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier(base_model)\n",
    "\n",
    "optimizer = K.optimizers.Adam(\n",
    "    learning_rate=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd1256c9-8a69-47a9-94a1-f6d3c401d1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = gd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d862f19f-de66-4020-9f73-f49b53dca5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build([None, None, 1])\n",
    "model.compile(loss=K.losses.BinaryCrossentropy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aam",
   "language": "python",
   "name": "aam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
